#+title: Measuring evaluation times

This example involves simulating trees of varying sizes and then timing how long
it takes to evaluate the likelihood function on the resulting data set using our
approximation. There are instructions for timing the evaluation times using the
algorithm described by Manceau /et al/ (2020) included here as well. We refer to
that as the =popsize-distribution= since that is the name of the repository in
which it is implemented.

** Configure the evaluation

The whole computation is configured by a JSON file generated by the
=make-json-config.R= script. This makes it easy to control the whole computation
from a single place. For example, the value associated with =acNumSims= controls
how many simulations are run. This is set to 2000, but if you only wanted to
test the code is running you can reduce this to 20 and still get a reasonable
result.

#+BEGIN_SRC sh :tangle main.sh
Rscript src/make-json-config.R
#+END_SRC

** Running the BDSCOD profiling

The profiling of the Haskell code is done using the =criterion= profiling
package which provides a CLI (which is why there is long =stack exec= command)
used in the following =main.sh= script.

#+BEGIN_SRC sh :tangle main.sh
stack build 

rm -f out/*
rm -f fibber.html 
rm -f fobber.csv 

stack exec -- timing-evaluation --output fibber.html --csv fobber.csv --time-limit 5 
#+END_SRC

The files =fibber.html= and =fobber.csv= are used by =criterion= to write output
to. At this point you can open =fibber.html= in a browser to see the results.
The next steps are used to do the analogous timing in python.

To put these simulations into a format that is easy to use with Manceau's code
we run the following script

#+BEGIN_SRC sh :tangle main.sh
Rscript src/prepare-simulations-for-popsize.R
#+END_SRC

*NOTE* that =popsize-distribution= appears to treat the origin as birth event.

** Running Manceau's approximation

You can get a copy of =popsize-distribution= from [[https://gitlab.com/MMarc/popsize-distribution][the author's gitlab]] or from my
fork of it [[https://gitlab.com/aezarebski/popsize-distribution][here]]. To the best of my knowledge, my fork is in the same state as
the one used to generate the results of Manceau /et al/ (2020).

*REMEMBER TO SOURCE THE VIRTUAL ENVIRONMENT!*

To compute the evaluation times for the =popsize-distribuion= function, you need
to clone the correct repository into the current directory and then set up the
necessary python environment (there is a =requirements.txt= provided). Then
after running the BDSCOD timing, you need to adjust the simulation files and run
=run-python-timing.sh= from withing =popsize-distribution= to generate the
timing results.

The output of =pip freeze= for the virtual environment being used is here, i.e.,
the =requirements.txt= is given below.

#+begin_src sh
python3 -m venv venv
source venv/bin/activate
pip install -U pip
pip install -r requirements.txt
#+end_src

where the =requirements.txt= is as follows.

#+BEGIN_SRC :tangle requirements.txt
cycler==0.10.0
Cython==0.29.21
ete3==3.1.1
kiwisolver==1.1.0
matplotlib==3.0.3
numpy==1.18.5
pkg-resources==0.0.0
pyparsing==2.4.7
python-dateutil==2.8.1
scipy==1.4.1
six==1.15.0
#+END_SRC

To actually run the this, you need to clone the =popsize-distribution=
repository and copy over a couple of helper scripts as follows. The commit for
=popsize-distribution= I used is =5223bd2812423c9be0c3086a30df25699cedcdda=.

#+BEGIN_SRC sh
git clone https://gitlab.com/MMarc/popsize-distribution.git

cd popsize-distribution 

cp ../timing.py .
cp ../run-python-timing.sh

./run-python-timing.sh
#+END_SRC

This might take a while... After this we can leave the =popsize-distribution=
directory and deactivate the python virtual environment.

#+BEGIN_SRC sh
cd ../
deactivate
#+END_SRC

** Generating summary plots

The final step is to generate figures to display the results this is done using
the R scripts in the =src= directory. Don't forget that there is a =shell.nix=
file in the root of this repository to specify the R environment, although there
is nothing fancy so this should run in most R versions.

#+BEGIN_SRC 
Rscript src/plot-profiles.R
Rscript src/plot-llhds.R
#+END_SRC

*** Issues with SVG plots

The script =plot-llhds.R= file generates output in several formats: PDF, PNG and
SVG. If you get an error about one of the formats you can comment out the line
to save the figures in that format.

** Results

Since the whole point of this is the timing of the two methods, lets look first
at how the timings compare. Note that this figure is produced by
=src/plot-profiles.R=.

[[./out/profiles.png]]

But of course, the benefits of a faster algorithm are only meaningful if it
gives the correct results so lets look at a comparison of the LLHD across the
two methods. There appears to be an additive constant that differs between the
two methods, but this wsa also present in Marc's code so I suspect there is
something about numerical stability in his code that accounts for this.

[[./out/llhd-comparison.png]]

Finally, let's consider how the selected truncation parameter differs with the
size of the data set, since this is a novel result too.

[[./out/truncation-comparison.png]]

** Parameters

The parameters used in this computation are defined in a JSON file,
=app-config.json= which is generated by =src/make-json-config.R=.

** Understanding output files

In addition to the [[*Configure the evaluation][configuration file]] for this example, there are several JSON
files used to store intermediate results. Below is a brief description of these
files and their structure, since these are only intermediate files this
information is liable to go out of date quickly so please be careful.

- =out/simulation-sizes-and-lllhds.csv= is a table where each row contains the
  size of the simulation (the number of observations in the simulated dataset),
  the log-likelihood of the simulated data (calculated using TimTam) and the
  path to the file which contains the observations for that simulation.
- =out/simulated-observations-xxxxx.json= contains a list of records describing
  the observations in simulation number =xxxxx=. Each of these records
  represents an =Observation= value. These values contains two pieces of
  information: the /delay/ since the last observation, and a description of the
  observation. There is an [[*=Observation= output example][example below]].
- =out/reformated-simulated-observations-xxxxx.json= contains the same data as
  the previous file but has been reformated in a way that is easier for
  =popsize-distribution= to use. There is an [[*=popsize-distribution= output example][example below]].
- =fobber.csv= is a file generated by =criterion= which specifies the time
  required to evaluate the log-likelihood function for each data set.
- =out/popsize-distribution-timing-xxxx.json= describes the results of finding
  an appropriate truncation parameter and the results of timing the evaluation
  of the likelihood using =popsize-distribution=.

*** =Observation= output example

The observations in the simulation are written to a JSON file. The following
snippet shows an (abbreviated) example of what one of these files might look
like.

#+begin_src json
[
    [0.75, {
        "tag": "OBirth"
    }],
    [1.63, {
        "tag": "OBirth"
    }],
    ...
    ...
    ...
    [8.16e-3, {
        "tag": "OOccurrence"
    }],
    [1.48e-3, {
        "tag": "ObsUnscheduledSequenced"
    }],
    ...
    ...
    ...
    [6.00e-2, {
        "tag": "OBirth"
    }],
    [6.54e-4, {
        "tag": "OCatastrophe",
        "contents": 38
    }]
]
#+end_src

Each element of this list corresponds to a single =Observation=. Each
observation contains two pieces of information: the first specifies how much
time passed since the last observation, the second describes the observation
that was made. For example in the second element in the example above,

#+begin_src json
    [1.63, {
        "tag": "OBirth"
    }],
#+end_src

a birth event was observed 1.63 units of time after the previous event. For
births, unscheduled sequenced and unscheduled unsequenced (A.K.A. occurrence)
events, only a single individual is ever observed so it is sufficient to just
describe the type of observation. In the case of the scheduled sequenced
observation, (A.K.A. the catastrophe) additional information is required to
specify how many individuals where observed. This is why there is the integer 38
associated with the final observation.

#+begin_src json
    [6.54e-4, {
        "tag": "OCatastrophe",
        "contents": 38
    }]
#+end_src

*** =popsize-distribution= output example

The reformated observations are written to a JSON file with the following
structure.

#+begin_src json
{
    "OBirth": [...],
    "OOccurrence": [...],
    "ObsUnscheduledSequenced": [...],
    "OCatastrophe": [...]
}
#+end_src

Each list contains the times at which this type of event was observed. For
example, the list of values for =OBirth= contains the times at which birth
events occurred in the reconstructed tree. *NOTE* that these times are all
backwards from the present which is given time 0.
